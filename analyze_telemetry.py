#!/usr/bin/env python3
"""
Copilot é¥æµ‹æ•°æ®åˆ†æå·¥å…·

ç”¨äºåˆ†æä¿å­˜çš„é¥æµ‹JSONæ–‡ä»¶ï¼Œæå–ç”¨æˆ·ä½¿ç”¨ç»Ÿè®¡æ•°æ®

ä½¿ç”¨æ–¹æ³•:
1. åˆ†æç‰¹å®šæ—¥æœŸçš„æ•°æ®: python analyze_telemetry.py --date 20250803
2. åˆ†æç‰¹å®šç”¨æˆ·çš„æ•°æ®: python analyze_telemetry.py --user username
3. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š: python analyze_telemetry.py --report
4. åˆ†ææœ€è¿‘Nå¤©çš„æ•°æ®: python analyze_telemetry.py --days 7
"""

import json
import os
import argparse
import glob
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import pandas as pd

class TelemetryAnalyzer:
    def __init__(self, data_dir="copilot_telemetry_data"):
        self.data_dir = data_dir
        self.summary_data = []
        
    def load_summary_log(self):
        """åŠ è½½æ±‡æ€»æ—¥å¿—æ–‡ä»¶"""
        summary_file = os.path.join(self.data_dir, "w.log")
        if not os.path.exists(summary_file):
            print(f"æ±‡æ€»æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {summary_file}")
            return []
        
        summary_data = []
        with open(summary_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    entry = json.loads(line.strip())
                    summary_data.append(entry)
                except json.JSONDecodeError:
                    continue
        
        self.summary_data = summary_data
        return summary_data
    
    def get_files_by_date(self, target_date):
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰æ–‡ä»¶"""
        date_dir = os.path.join(self.data_dir, target_date)
        if not os.path.exists(date_dir):
            return []
        
        files = glob.glob(os.path.join(date_dir, "telemetry_*.json"))
        return files
    
    def get_files_by_user(self, username):
        """è·å–æŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰æ–‡ä»¶"""
        files = []
        for entry in self.summary_data:
            if entry.get("username") == username:
                files.append(entry.get("filename"))
        return [f for f in files if f and os.path.exists(f)]
    
    def get_files_by_days(self, days):
        """è·å–æœ€è¿‘Nå¤©çš„æ‰€æœ‰æ–‡ä»¶"""
        files = []
        target_dates = []
        
        for i in range(days):
            date = (datetime.now() - timedelta(days=i)).strftime("%Y%m%d")
            target_dates.append(date)
        
        for date in target_dates:
            files.extend(self.get_files_by_date(date))
        
        return files
    
    def analyze_file(self, filename):
        """åˆ†æå•ä¸ªJSONæ–‡ä»¶"""
        if not os.path.exists(filename):
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            return None
        
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            metadata = data.get("metadata", {})
            telemetry_objects = data.get("telemetry_objects", [])
            
            analysis = {
                "filename": filename,
                "metadata": metadata,
                "total_events": len(telemetry_objects),
                "event_types": defaultdict(int),
                "copilot_events": {
                    "completions_shown": 0,
                    "completions_accepted": 0,
                    "characters_shown": 0,
                    "characters_accepted": 0,
                    "lines_shown": 0,
                    "lines_accepted": 0
                },
                "languages": defaultdict(int),
                "editors": defaultdict(int)
            }
            
            # åˆ†ææ¯ä¸ªé¥æµ‹å¯¹è±¡
            for obj in telemetry_objects:
                try:
                    base_data = obj.get("data", {}).get("baseData", {})
                    event_name = base_data.get("name", "unknown")
                    analysis["event_types"][event_name] += 1
                    
                    # æå–Copilotç›¸å…³æŒ‡æ ‡
                    if "shown" in event_name.lower():
                        analysis["copilot_events"]["completions_shown"] += 1
                        measurements = base_data.get("measurements", {})
                        analysis["copilot_events"]["characters_shown"] += measurements.get("compCharLen", 0)
                        analysis["copilot_events"]["lines_shown"] += measurements.get("numLines", 0)
                    
                    elif "accepted" in event_name.lower():
                        analysis["copilot_events"]["completions_accepted"] += 1
                        measurements = base_data.get("measurements", {})
                        analysis["copilot_events"]["characters_accepted"] += measurements.get("compCharLen", 0)
                        analysis["copilot_events"]["lines_accepted"] += measurements.get("numLines", 0)
                    
                    # æå–è¯­è¨€å’Œç¼–è¾‘å™¨ä¿¡æ¯
                    properties = base_data.get("properties", {})
                    language = properties.get("languageId", "unknown")
                    editor_version = properties.get("editor_version", "unknown")
                    
                    if language != "unknown":
                        analysis["languages"][language] += 1
                    
                    if "/" in editor_version:
                        editor = editor_version.split("/")[0]
                        analysis["editors"][editor] += 1
                        
                except Exception as e:
                    print(f"åˆ†æå¯¹è±¡æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            return analysis
            
        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def analyze_multiple_files(self, files):
        """åˆ†æå¤šä¸ªæ–‡ä»¶å¹¶æ±‡æ€»"""
        all_analyses = []
        summary = {
            "total_files": len(files),
            "total_events": 0,
            "event_types": defaultdict(int),
            "copilot_summary": {
                "completions_shown": 0,
                "completions_accepted": 0,
                "characters_shown": 0,
                "characters_accepted": 0,
                "lines_shown": 0,
                "lines_accepted": 0,
                "acceptance_rate": 0.0
            },
            "languages": defaultdict(int),
            "editors": defaultdict(int),
            "users": set(),
            "date_range": {"start": None, "end": None}
        }
        
        for filename in files:
            analysis = self.analyze_file(filename)
            if analysis:
                all_analyses.append(analysis)
                
                # æ±‡æ€»æ•°æ®
                summary["total_events"] += analysis["total_events"]
                
                for event_type, count in analysis["event_types"].items():
                    summary["event_types"][event_type] += count
                
                for key, value in analysis["copilot_events"].items():
                    summary["copilot_summary"][key] += value
                
                for lang, count in analysis["languages"].items():
                    summary["languages"][lang] += count
                
                for editor, count in analysis["editors"].items():
                    summary["editors"][editor] += count
                
                # æ·»åŠ ç”¨æˆ·
                username = analysis["metadata"].get("username")
                if username:
                    summary["users"].add(username)
                
                # æ›´æ–°æ—¥æœŸèŒƒå›´
                timestamp = analysis["metadata"].get("timestamp")
                if timestamp:
                    if not summary["date_range"]["start"] or timestamp < summary["date_range"]["start"]:
                        summary["date_range"]["start"] = timestamp
                    if not summary["date_range"]["end"] or timestamp > summary["date_range"]["end"]:
                        summary["date_range"]["end"] = timestamp
        
        # è®¡ç®—æ¥å—ç‡
        if summary["copilot_summary"]["completions_shown"] > 0:
            summary["copilot_summary"]["acceptance_rate"] = (
                summary["copilot_summary"]["completions_accepted"] / 
                summary["copilot_summary"]["completions_shown"] * 100
            )
        
        summary["users"] = list(summary["users"])
        return summary, all_analyses
    
    def generate_report(self, summary, output_file=None):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("Copilot é¥æµ‹æ•°æ®åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        
        # åŸºæœ¬ç»Ÿè®¡
        report.append("ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        report.append(f"  æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        report.append(f"  æ€»äº‹ä»¶æ•°: {summary['total_events']}")
        report.append(f"  ç”¨æˆ·æ•°é‡: {len(summary['users'])}")
        report.append(f"  æ—¥æœŸèŒƒå›´: {summary['date_range']['start']} åˆ° {summary['date_range']['end']}")
        report.append("")
        
        # Copilot ä½¿ç”¨ç»Ÿè®¡
        report.append("ğŸ¤– Copilot ä½¿ç”¨ç»Ÿè®¡:")
        copilot = summary["copilot_summary"]
        report.append(f"  ä»£ç å»ºè®®æ˜¾ç¤ºæ¬¡æ•°: {copilot['completions_shown']}")
        report.append(f"  ä»£ç å»ºè®®æ¥å—æ¬¡æ•°: {copilot['completions_accepted']}")
        report.append(f"  æ¥å—ç‡: {copilot['acceptance_rate']:.2f}%")
        report.append(f"  æ˜¾ç¤ºå­—ç¬¦æ•°: {copilot['characters_shown']}")
        report.append(f"  æ¥å—å­—ç¬¦æ•°: {copilot['characters_accepted']}")
        report.append(f"  æ˜¾ç¤ºè¡Œæ•°: {copilot['lines_shown']}")
        report.append(f"  æ¥å—è¡Œæ•°: {copilot['lines_accepted']}")
        report.append("")
        
        # ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡
        report.append("ğŸ’» ç¼–ç¨‹è¯­è¨€ä½¿ç”¨ç»Ÿè®¡:")
        for lang, count in sorted(summary["languages"].items(), key=lambda x: x[1], reverse=True)[:10]:
            report.append(f"  {lang}: {count} æ¬¡")
        report.append("")
        
        # ç¼–è¾‘å™¨ç»Ÿè®¡
        report.append("ğŸ”§ ç¼–è¾‘å™¨ä½¿ç”¨ç»Ÿè®¡:")
        for editor, count in sorted(summary["editors"].items(), key=lambda x: x[1], reverse=True):
            report.append(f"  {editor}: {count} æ¬¡")
        report.append("")
        
        # äº‹ä»¶ç±»å‹ç»Ÿè®¡
        report.append("ğŸ“ äº‹ä»¶ç±»å‹ç»Ÿè®¡ (Top 10):")
        for event_type, count in sorted(summary["event_types"].items(), key=lambda x: x[1], reverse=True)[:10]:
            report.append(f"  {event_type}: {count} æ¬¡")
        report.append("")
        
        # ç”¨æˆ·åˆ—è¡¨
        report.append("ğŸ‘¥ ç”¨æˆ·åˆ—è¡¨:")
        for user in sorted(summary["users"]):
            report.append(f"  {user}")
        
        report_text = "\n".join(report)
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
            print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            print(report_text)
        
        return report_text


def main():
    parser = argparse.ArgumentParser(description="Copilot é¥æµ‹æ•°æ®åˆ†æå·¥å…·")
    parser.add_argument("--date", help="åˆ†ææŒ‡å®šæ—¥æœŸçš„æ•°æ® (æ ¼å¼: YYYYMMDD)")
    parser.add_argument("--user", help="åˆ†ææŒ‡å®šç”¨æˆ·çš„æ•°æ®")
    parser.add_argument("--days", type=int, help="åˆ†ææœ€è¿‘Nå¤©çš„æ•°æ®")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆå®Œæ•´æŠ¥å‘Š")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    analyzer = TelemetryAnalyzer()
    analyzer.load_summary_log()
    
    files = []
    
    if args.date:
        files = analyzer.get_files_by_date(args.date)
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ (æ—¥æœŸ: {args.date})")
    elif args.user:
        files = analyzer.get_files_by_user(args.user)
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ (ç”¨æˆ·: {args.user})")
    elif args.days:
        files = analyzer.get_files_by_days(args.days)
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ (æœ€è¿‘ {args.days} å¤©)")
    elif args.report:
        # åˆ†ææ‰€æœ‰å¯ç”¨æ–‡ä»¶
        all_files = glob.glob("copilot_telemetry_data/*/telemetry_*.json")
        files = all_files
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ (æ‰€æœ‰æ•°æ®)")
    else:
        print("è¯·æŒ‡å®šåˆ†æå‚æ•°ã€‚ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯ã€‚")
        return
    
    if not files:
        print("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚")
        return
    
    print("æ­£åœ¨åˆ†ææ•°æ®...")
    summary, analyses = analyzer.analyze_multiple_files(files)
    
    output_file = args.output if args.output else None
    analyzer.generate_report(summary, output_file)


if __name__ == "__main__":
    main()
