#!/usr/bin/env python3
"""
Copilot é¥æµ‹æ•°æ®åˆ†æå·¥å…·

ç”¨äºåˆ†æä¿å­˜çš„é¥æµ‹JSONæ–‡ä»¶ï¼Œæå–ç”¨æˆ·ä½¿ç”¨Copilotçš„ç”¨é‡æ•°æ®

ä½¿ç”¨æ–¹æ³•:
    python telemetry_analyzer.py --date 20250804 --user username
    python telemetry_analyzer.py --all
"""

import json
import os
import argparse
from datetime import datetime, timedelta
from collections import defaultdict
import glob

class TelemetryAnalyzer:
    def __init__(self, data_dir="copilot_telemetry_data"):
        self.data_dir = data_dir
        
    def get_files_by_date(self, date_str=None):
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰é¥æµ‹æ–‡ä»¶"""
        if date_str:
            pattern = f"{self.data_dir}/{date_str}/telemetry_*.json"
        else:
            pattern = f"{self.data_dir}/*/telemetry_*.json"
        
        return glob.glob(pattern)
    
    def load_telemetry_file(self, file_path):
        """åŠ è½½å•ä¸ªé¥æµ‹æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"æ— æ³•åŠ è½½æ–‡ä»¶ {file_path}: {e}")
            return None
    
    def analyze_usage_summary(self, date_str=None, username=None):
        """åˆ†æç”¨é‡æ±‡æ€»"""
        files = self.get_files_by_date(date_str)
        
        total_stats = {
            "total_files": 0,
            "total_events": 0,
            "users": defaultdict(int),
            "event_types": defaultdict(int),
            "dates": defaultdict(int),
            "connections": set(),
            "accepted_stats": {
                "total_lines": 0,
                "total_chars": 0,
                "count": 0
            },
            "shown_stats": {
                "total_lines": 0,
                "total_chars": 0,
                "count": 0
            },
            "languages": defaultdict(int),
            "editors": defaultdict(int)
        }
        
        for file_path in files:
            data = self.load_telemetry_file(file_path)
            if not data:
                continue
                
            # è¿‡æ»¤ç”¨æˆ·
            if username and data["metadata"]["username"] != username:
                continue
                
            total_stats["total_files"] += 1
            total_stats["total_events"] += data["metadata"]["total_objects"]
            total_stats["users"][data["metadata"]["username"]] += data["metadata"]["total_objects"]
            
            # æå–æ—¥æœŸ
            file_date = data["metadata"]["timestamp"][:10]  # YYYY-MM-DD
            total_stats["dates"][file_date] += data["metadata"]["total_objects"]
            
            # è¿æ¥ID
            total_stats["connections"].add(data["metadata"]["connectionid"])
            
            # äº‹ä»¶ç±»å‹ç»Ÿè®¡
            for event_type, count in data["raw_statistics"]["events_by_type"].items():
                total_stats["event_types"][event_type] += count
            
            # åˆ†æå…·ä½“çš„é¥æµ‹å¯¹è±¡
            for obj in data["telemetry_objects"]:
                if isinstance(obj, dict):
                    try:
                        base_data = obj.get("data", {}).get("baseData", {})
                        event_name = base_data.get("name", "")
                        
                        # ç»Ÿè®¡æ¥å—å’Œæ˜¾ç¤ºçš„æ•°æ®
                        if "accepted" in event_name.lower():
                            measurements = base_data.get("measurements", {})
                            lines = measurements.get("numLines", 0)
                            chars = measurements.get("compCharLen", 0)
                            if lines > 0:
                                total_stats["accepted_stats"]["total_lines"] += lines
                                total_stats["accepted_stats"]["total_chars"] += chars
                                total_stats["accepted_stats"]["count"] += 1
                        
                        elif "shown" in event_name.lower():
                            measurements = base_data.get("measurements", {})
                            lines = measurements.get("numLines", 0)
                            chars = measurements.get("compCharLen", 0)
                            if lines > 0:
                                total_stats["shown_stats"]["total_lines"] += lines
                                total_stats["shown_stats"]["total_chars"] += chars
                                total_stats["shown_stats"]["count"] += 1
                        
                        # è¯­è¨€å’Œç¼–è¾‘å™¨ç»Ÿè®¡
                        properties = base_data.get("properties", {})
                        if properties:
                            lang = properties.get("languageId", "unknown")
                            editor_version = properties.get("editor_version", "unknown")
                            
                            total_stats["languages"][lang] += 1
                            total_stats["editors"][editor_version] += 1
                            
                    except Exception as e:
                        continue
        
        return total_stats
    
    def print_summary(self, stats):
        """æ‰“å°æ±‡æ€»ç»Ÿè®¡"""
        print("=" * 60)
        print("Copilot é¥æµ‹æ•°æ®åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        
        print(f"\nğŸ“ æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"  æ€»äº‹ä»¶æ•°: {stats['total_events']}")
        print(f"  è¿æ¥æ•°: {len(stats['connections'])}")
        
        print(f"\nğŸ‘¤ ç”¨æˆ·ç»Ÿè®¡:")
        for user, count in sorted(stats['users'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {user}: {count} äº‹ä»¶")
        
        print(f"\nğŸ“… æ—¥æœŸç»Ÿè®¡:")
        for date, count in sorted(stats['dates'].items()):
            print(f"  {date}: {count} äº‹ä»¶")
        
        print(f"\nğŸ”„ äº‹ä»¶ç±»å‹ç»Ÿè®¡:")
        for event_type, count in sorted(stats['event_types'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {event_type}: {count} æ¬¡")
        
        print(f"\nâœ… æ¥å—ç»Ÿè®¡:")
        accepted = stats['accepted_stats']
        if accepted['count'] > 0:
            print(f"  æ¥å—æ¬¡æ•°: {accepted['count']}")
            print(f"  æ€»è¡Œæ•°: {accepted['total_lines']}")
            print(f"  æ€»å­—ç¬¦æ•°: {accepted['total_chars']}")
            print(f"  å¹³å‡è¡Œæ•°/æ¬¡: {accepted['total_lines'] / accepted['count']:.2f}")
            print(f"  å¹³å‡å­—ç¬¦æ•°/æ¬¡: {accepted['total_chars'] / accepted['count']:.2f}")
        else:
            print("  æ— æ¥å—æ•°æ®")
        
        print(f"\nğŸ‘ æ˜¾ç¤ºç»Ÿè®¡:")
        shown = stats['shown_stats']
        if shown['count'] > 0:
            print(f"  æ˜¾ç¤ºæ¬¡æ•°: {shown['count']}")
            print(f"  æ€»è¡Œæ•°: {shown['total_lines']}")
            print(f"  æ€»å­—ç¬¦æ•°: {shown['total_chars']}")
            print(f"  å¹³å‡è¡Œæ•°/æ¬¡: {shown['total_lines'] / shown['count']:.2f}")
            print(f"  å¹³å‡å­—ç¬¦æ•°/æ¬¡: {shown['total_chars'] / shown['count']:.2f}")
        else:
            print("  æ— æ˜¾ç¤ºæ•°æ®")
        
        # è®¡ç®—æ¥å—ç‡
        if shown['count'] > 0 and accepted['count'] > 0:
            acceptance_rate = (accepted['count'] / shown['count']) * 100
            print(f"\nğŸ“Š æ¥å—ç‡: {acceptance_rate:.2f}%")
        
        print(f"\nğŸ’» è¯­è¨€ç»Ÿè®¡:")
        for lang, count in sorted(stats['languages'].items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  {lang}: {count} æ¬¡")
        
        print(f"\nğŸ–¥ ç¼–è¾‘å™¨ç»Ÿè®¡:")
        for editor, count in sorted(stats['editors'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {editor}: {count} æ¬¡")
    
    def generate_daily_report(self, date_str):
        """ç”ŸæˆæŒ‡å®šæ—¥æœŸçš„è¯¦ç»†æŠ¥å‘Š"""
        stats = self.analyze_usage_summary(date_str)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = f"copilot_analysis_report_{date_str}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            # å°†setè½¬æ¢ä¸ºlistä»¥ä¾¿JSONåºåˆ—åŒ–
            stats_for_json = dict(stats)
            stats_for_json['connections'] = list(stats['connections'])
            json.dump(stats_for_json, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        return stats

def main():
    parser = argparse.ArgumentParser(description='Copilot é¥æµ‹æ•°æ®åˆ†æå·¥å…·')
    parser.add_argument('--date', help='åˆ†ææŒ‡å®šæ—¥æœŸçš„æ•°æ® (æ ¼å¼: YYYYMMDD)')
    parser.add_argument('--user', help='åˆ†ææŒ‡å®šç”¨æˆ·çš„æ•°æ®')
    parser.add_argument('--all', action='store_true', help='åˆ†ææ‰€æœ‰æ•°æ®')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    analyzer = TelemetryAnalyzer()
    
    if args.all:
        stats = analyzer.analyze_usage_summary()
    else:
        stats = analyzer.analyze_usage_summary(args.date, args.user)
    
    analyzer.print_summary(stats)
    
    if args.report:
        date_str = args.date or datetime.now().strftime("%Y%m%d")
        analyzer.generate_daily_report(date_str)

if __name__ == "__main__":
    main()
